bigdata-命令-02.txt


清空/temp/* 目录
/home/hadoop/shell/batch/bigdata/delete-tmp.sh(一般不需要清理)
清空日志
  /home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/hadoop/delete-logs.sh

jdk
------------------------------------------------------------------------------------------------------------------
重新安装jdk                  /home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/jdk/jdk_reinstall.sh
global
------------------------------------------------------------------------------------------------------------------
配置bashrc环境变量配置文件             /home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/global/bashrc.sh

scala
------------------------------------------------------------------------------------------------------------------
重新安装集群每一个节点上的scala
	/home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/scala/scala_reinstall.sh

hadoop
------------------------------------------------------------------------------------------------------------------
安使化集群，同步集群，安装包，到安装前（前提先配好一台）
	/home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/hadoop/hadoop_init.sh

同步集群配置文件
	/home/hadoop/workspaces/github/opensourceteams/notes/shell-3/batch/hadoop/scp-hadoop-ect.sh


查看dfs目录结构
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/bin/hadoop fs -ls -R /
上传文件到dfs(先将文件传到服务器上的普通目录下，再传到dfs目录)
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/bin/hadoop fs -put ~/temp/wordCount.txt   /library/wordcount/input/Data/	
查看文件内容信息
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/hadoop dfs -cat  /bigdata/examples/hadoop/hadoop1/wordcount/input/file01


	
格式化
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/bin/hdfs namenode -format
启动
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/start-all.sh
	或者
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/start-dfs.sh
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/start-yarn.sh
停止
	/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/stop-all.sh
	或者
		/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/stop-dfs.sh
		/opt/modules/bigdata/hadoop/hadoop-2.6.0/sbin/stop-yarn.sh



spark
------------------------------------------------------------------------------------------------------------------
     新建目录供spark专用
     	/opt/modules/bigdata/hadoop/hadoop-2.6.0/bin/hadoop fs -mkdir -p    /historyserverforSpark
     	/opt/modules/bigdata/hadoop/hadoop-2.6.0/bin/hadoop fs -put ~/temp/wordCount.txt   /library/wordcount/input/Data
	
     ).同步spark配置文件
           /home/hadoop/shell/batch/spark/scp-spark-conf.sh

     ).spark-shell
             	/opt/modules/bigdata/spark/spark-1.6.0-bin-hadoop2.6/bin/spark-shell  --master spark://s0:7077  
             	http://S20:4040 

	 ).启动spark  /opt/modules/bigdata/spark/spark-1.6.0-bin-hadoop2.6/sbin/start-all.sh
	 ).关闭spark  /opt/modules/bigdata/spark/spark-1.6.0-bin-hadoop2.6/sbin/stop-all.sh

	 ).启动历史记录服务  /opt/modules/bigdata/spark/spark-1.6.0-bin-hadoop2.6/sbin/start-history-server.sh
	 ).关闭历史记录服务  /opt/modules/bigdata/spark/spark-1.6.0-bin-hadoop2.6/sbin/stop-history-server.sh
	 ).访问  http://S20:18080  
	 ).访问  http://S20:8080
